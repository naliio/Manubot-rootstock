{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLGkt5qiyz4E"
      },
      "source": [
        "# Introduction to BNNs with Larq\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/larq/docs/blob/master/docs/larq/tutorials/mnist.ipynb\"><button class=\"notebook-badge\">Run on Colab</button></a> <a href=\"https://github.com/larq/docs/blob/master/docs/larq/tutorials/mnist.ipynb\"><button class=\"notebook-badge\">View on GitHub</button></a>\n",
        "\n",
        "This tutorial demonstrates how to train a simple binarized Convolutional Neural Network (CNN) to classify MNIST digits. This simple network will achieve approximately 98% accuracy on the MNIST test set. This tutorial uses Larq and the [Keras Sequential API](https://www.tensorflow.org/guide/keras), so creating and training our model will require only a few lines of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soSAGDtnJqzw"
      },
      "outputs": [],
      "source": [
        "pip install larq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import larq as lq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRFxccghyMVo"
      },
      "source": [
        "### Download and prepare the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWoEqyMuXFF4"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# Normalize pixel values to be between -1 and 1\n",
        "train_images, test_images = train_images / 127.5 - 1, test_images / 127.5 - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oewp-wYg31t9"
      },
      "source": [
        "### Create the model\n",
        "\n",
        "The following will create a simple binarized CNN.\n",
        "\n",
        "The quantization function\n",
        "$$\n",
        "q(x) = \\begin{cases}\n",
        "    -1 & x < 0 \\\\\\\n",
        "    1 & x \\geq 0\n",
        "\\end{cases}\n",
        "$$\n",
        "is used in the forward pass to binarize the activations and the latent full precision weights. The gradient of this function is zero almost everywhere which prevents the model from learning.\n",
        "\n",
        "To be able to train the model the gradient is instead estimated using the Straight-Through Estimator (STE)\n",
        "(the binarization is essentially replaced by a clipped identity on the backward pass):\n",
        "$$\n",
        "\\frac{\\partial q(x)}{\\partial x} = \\begin{cases}\n",
        "    1 & \\left|x\\right| \\leq 1 \\\\\\\n",
        "    0 & \\left|x\\right| > 1\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "In Larq this can be done by using `input_quantizer=\"ste_sign\"` and `kernel_quantizer=\"ste_sign\"`.\n",
        "Additionally, the latent full precision weights are clipped to -1 and 1 using `kernel_constraint=\"weight_clip\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9YmGQBQPrdn"
      },
      "outputs": [],
      "source": [
        "# All quantized layers except the first will use the same options\n",
        "kwargs = dict(input_quantizer=\"ste_sign\",\n",
        "              kernel_quantizer=\"ste_sign\",\n",
        "              kernel_constraint=\"weight_clip\")\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# In the first layer we only quantize the weights and not the input\n",
        "model.add(lq.layers.QuantConv2D(32, (3, 3),\n",
        "                                kernel_quantizer=\"ste_sign\",\n",
        "                                kernel_constraint=\"weight_clip\",\n",
        "                                use_bias=False,\n",
        "                                input_shape=(28, 28, 1)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(lq.layers.QuantDense(64, use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model.add(tf.keras.layers.Activation(\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvDVFkg-2DPm"
      },
      "source": [
        "Almost all parameters in the network are binarized, so either -1 or 1. This makes the network extremely fast if it would be deployed on custom BNN hardware.\n",
        "\n",
        " Here is the complete architecture of our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-C4XBg4UTJy"
      },
      "outputs": [],
      "source": [
        "lq.models.summary(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3odqfHP4M67"
      },
      "source": [
        "### Compile and train the model\n",
        "\n",
        "Note: This may take a few minutes depending on your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdDzI75PUXrG"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history=model.fit(train_images, train_labels, batch_size=64, epochs=6)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKgyC5K_4O0d"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LvwaKhtUdOo"
      },
      "outputs": [],
      "source": [
        "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fVLKyArCLfyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 遍历模型的每一层\n",
        "for i, layer in enumerate(model.layers):\n",
        "    # 检查是否是 QuantConv2D 层\n",
        "    if isinstance(layer, lq.layers.QuantConv2D):\n",
        "        # 提取权重\n",
        "        weights = layer.get_weights()\n",
        "\n",
        "        # 打印层索引和权重形状\n",
        "        print(f\"Layer {i} ({layer.name}) weights shape: {weights[0].shape}\")\n",
        "\n",
        "        # 打印权重值\n",
        "        print(\"Weights:\\n\", weights[0])"
      ],
      "metadata": {
        "id": "NXaJODaVMyrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import larq as lq\n",
        "\n",
        "# 遍历模型的每一层\n",
        "for i, layer in enumerate(model.layers):\n",
        "    # 检查是否是 QuantConv2D 层\n",
        "    if isinstance(layer, lq.layers.QuantConv2D):\n",
        "        # 提取浮点数权重\n",
        "        weights = layer.get_weights()[0]\n",
        "\n",
        "        # 使用 ste_sign 对权重进行量化\n",
        "        quantized_weights = lq.quantizers.ste_sign(weights)\n",
        "\n",
        "        # 打印量化后的权重\n",
        "        print(f\"Layer {i} ({layer.name}) quantized weights shape: {quantized_weights.shape}\")\n",
        "        print(\"Quantized weights:\\n\", quantized_weights)"
      ],
      "metadata": {
        "id": "THzX7OzsNk-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 假设输入数据为 X_test 的第一张图片\n",
        "input_data = test_images[0:1]  # 形状为 (1, 28, 28, 1)\n",
        "\n",
        "# 逐层计算输出\n",
        "output = input_data\n",
        "for i, layer in enumerate(model.layers):\n",
        "    # 如果是 QuantConv2D 层，使用量化后的权重\n",
        "    if isinstance(layer, lq.layers.QuantConv2D):\n",
        "        weights = layer.get_weights()[0]\n",
        "        quantized_weights = lq.quantizers.ste_sign(weights)\n",
        "\n",
        "        # 使用量化后的权重进行卷积\n",
        "        output = tf.nn.conv2d(output, quantized_weights, strides=layer.strides, padding=layer.padding.upper())\n",
        "\n",
        "    # 如果是 MaxPooling2D 层，进行最大池化\n",
        "    elif isinstance(layer, tf.keras.layers.MaxPooling2D):\n",
        "        output = tf.nn.max_pool2d(output, ksize=layer.pool_size, strides=layer.strides, padding=layer.padding.upper())\n",
        "\n",
        "    # 如果是 BatchNormalization 层，进行批量归一化\n",
        "    elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        output = tf.nn.batch_normalization(output, layer.moving_mean, layer.moving_variance, layer.beta, layer.gamma, layer.epsilon)\n",
        "\n",
        "    # 如果是 QuantDense 层，使用量化后的权重\n",
        "    elif isinstance(layer, lq.layers.QuantDense):\n",
        "        weights = layer.get_weights()[0]\n",
        "        quantized_weights = lq.quantizers.ste_sign(weights)\n",
        "\n",
        "        # 使用量化后的权重进行矩阵乘法\n",
        "        output = tf.matmul(output, quantized_weights)\n",
        "\n",
        "    # 如果是激活函数层，应用激活函数\n",
        "    elif isinstance(layer, tf.keras.layers.Activation):\n",
        "        output = layer.activation(output)\n",
        "\n",
        "    # 打印每一层的输出形状\n",
        "    print(f\"Layer {i} ({layer.name}) output shape: {output.shape}\")\n",
        "\n",
        "# 打印最终输出\n",
        "print(\"Final output:\\n\", output)"
      ],
      "metadata": {
        "id": "ObvCgzyPOWky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfJ8AR03gT5"
      },
      "source": [
        "As you can see, our simple binarized CNN has achieved a test accuracy of around 98 %. Not bad for a few lines of code!\n",
        "\n",
        "For information on converting Larq models to an optimized format and using or benchmarking them on Android or ARM devices, have a look at [this guide](https://docs.larq.dev/compute-engine/end_to_end/)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_to_cnns.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}